{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861c95e0-b109-423e-b7b7-2087a61a4956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Group 1: Chengxi Luo, Dooyeon Jeong, Elmer Rodriguez, Khawar Siddiqui\n",
    "#Topic: Hate Crime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac169108-2808-467d-84fe-0a7563347061",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sodapy import Socrata\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "HATECRIME_DATA_FILENAME = r\"data\\hatecrime_opennyc.csv\"\n",
    "#  if the file not exists, request the data from nyc open data.\n",
    "if not os.path.exists(HATECRIME_DATA_FILENAME):\n",
    "    client = Socrata(\"data.cityofnewyork.us\", None)\n",
    "\n",
    "    # total rows are 3575, so set limit=4000 to retrieve all data.\n",
    "    results = client.get(\"bqiq-cu78\", limit=4000)\n",
    "\n",
    "    # Convert to pandas DataFrame\n",
    "    results_df = pd.DataFrame.from_records(results)\n",
    "    results_df.to_csv(HATECRIME_DATA_FILENAME, index = False)\n",
    "\n",
    "# read data from csv file.\n",
    "df = pd.read_csv(HATECRIME_DATA_FILENAME)\n",
    "\n",
    "# clean data\n",
    "# for columnb \"patrol_borough_name\", remove some useless prefix in the data set. \n",
    "df[\"patrol_borough_name\"] = df[\"patrol_borough_name\"].apply(lambda x: x.replace(\"PATROL BORO \", \"\"))\n",
    "# drop 2025 data, as 2025 is incomplete\n",
    "df = df[df[\"complaint_year_number\"] != 2025]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff1f4a47-4056-4f7f-91f0-6cae8c127eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year_region = df.groupby([\"complaint_year_number\",\"patrol_borough_name\"])[\"full_complaint_id\"].count().unstack(level=\"patrol_borough_name\")\n",
    "# currently the columns name is patrol_borough_name. We don't need it so just remove it\n",
    "by_year_region.columns.name = None\n",
    "# calculate total\n",
    "by_year_region.loc['total'] = by_year_region.sum()\n",
    "# Rename columns for readability\n",
    "by_year_region.rename(columns={\n",
    "    \"BKLYN NORTH\": \"Brooklyn North\",\n",
    "    \"BKLYN SOUTH\": \"Brooklyn South\",\n",
    "    \"BRONX\": \"Bronx\",\n",
    "    \"MAN NORTH\": \"Manhattan North\",\n",
    "    \"MAN SOUTH\": \"Manhattan South\",\n",
    "    \"QUEENS NORTH\": \"Queens North\",\n",
    "    \"QUEENS SOUTH\": \"Queens South\",\n",
    "    \"STATEN ISLAND\": \"Staten Island\"\n",
    "}, inplace=True)\n",
    "by_year_region.to_csv(\"nyc_hate_crime_by_year_region.csv\")\n",
    "by_year_region\n",
    "\n",
    "# Figure 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30aa2dcf-6217-4ffc-ae20-a44d8c3b129d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df.value_counts(\"bias_motive_description\") use bias_motive_description as index, count as value.\n",
    "# reset index will make bias_motive_description a new column. and set the index with 0,1,....\n",
    "# Of course, it will also parse the series to a dataframe.\n",
    "bias_motive_df = df.value_counts(\"bias_motive_description\").reset_index()\n",
    "# calculate the percentage.\n",
    "bias_motive_df[\"percentage\"] = bias_motive_df.apply(lambda x: f\"{x[\"count\"] / bias_motive_df[\"count\"].sum() * 100:.2f}%\", axis = 1)\n",
    "bias_motive_df.to_csv(\"bias_motive.csv\")\n",
    "bias_motive_df\n",
    "\n",
    "# Figure 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64604a79-4628-4df9-aaae-24c0555fa850",
   "metadata": {},
   "outputs": [],
   "source": [
    "by_year = df.groupby([\"complaint_year_number\",\"bias_motive_description\"])[\"full_complaint_id\"].count().unstack(\"bias_motive_description\")\n",
    "# Only keep the majority.\n",
    "by_year = by_year[[\"ANTI-ASIAN\",\"ANTI-BLACK\",\"ANTI-MALE HOMOSEXUAL (GAY)\",\"ANTI-JEWISH\"]]\n",
    "by_year.columns.name = None\n",
    "by_year = by_year.astype(int)\n",
    "by_year.to_csv(\"hate_crime_bias_motive_description_by_year.csv\")\n",
    "by_year\n",
    "\n",
    "# Figure 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6f497f5-58ef-4df9-ae7d-ff7d474698e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index is the year, sort_index is sort the value by index\n",
    "# number of nyc anti-jewish each year.\n",
    "anti_jewish = df[df['bias_motive_description'] == \"ANTI-JEWISH\"]['complaint_year_number'].value_counts().sort_index()\n",
    "# number of nyc hate crime each year.\n",
    "hate_crime = df['complaint_year_number'].value_counts().sort_index()\n",
    "\n",
    "hate_crime\n",
    "# Table 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f0f2263-bd2b-4232-8b7a-bc3528571e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use lambda as a variable, very easy to understand I guess.\n",
    "parse_pct = lambda x: (f\"{x * 100:.2f}%\" if not pd.isna(x) else \"N/A\")\n",
    "# get percent change data of both hate crime total incidents and anti-jewish inicdents.\n",
    "hate_crime_change = hate_crime.pct_change().apply(parse_pct)\n",
    "anti_jewish_change = anti_jewish.pct_change().apply(parse_pct)\n",
    "con = pd.concat([hate_crime,hate_crime_change,anti_jewish,anti_jewish_change],axis=1)\n",
    "\n",
    "# change column names.\n",
    "con.columns = [\"Hate Crime Incidents\",\"Hate Crime Incidents Change\",\"ANTI-Jewish Hate Crime Incidents\",\"ANTI-Jewish Hate Crime Incidents Change\"]\n",
    "# write to csv files.\n",
    "con.to_csv(\"hate_crime_and_anti_jewish_yearly_change.csv\")\n",
    "# set index name to none would looks better.\n",
    "con.index.name = None\n",
    "con\n",
    "\n",
    "# Table 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a612e6bf-8f04-44e5-93fb-a3729acfef31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of nyc hate crime in 2023. This variable is created for generating Figure 1\n",
    "# Since the dataset I use for the Figure 1 has no 2023 hate crime data in nyc.\n",
    "number_of_nyc_hate_crime_2023 = hate_crime[2023]\n",
    "number_of_nyc_hate_crime_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5eee6f1-0cc6-46ba-9c89-881d25be09fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "HATE_CRIME_BIAS_TYPE2023 = r\"data\\hate_crime_bias_type_2023.xlsx\"\n",
    "\n",
    "# if file doesn't exist, get the data from url, write it into a file\n",
    "if not os.path.exists(HATE_CRIME_BIAS_TYPE2023):\n",
    "    res = requests.get(\"https://www.criminaljustice.ny.gov/crimnet/ojsa/hatecrimesbiastype2023.xlsx\")\n",
    "    # write + binary mode\n",
    "    with open(HATE_CRIME_BIAS_TYPE2023, \"wb\") as f:\n",
    "        f.write(res.content)\n",
    "\n",
    "# read the file we downloaded.\n",
    "df = pd.read_excel(HATE_CRIME_BIAS_TYPE2023)\n",
    "\n",
    "# get the row which contains the data of total_incidents.\n",
    "total_incidents_row = df.iloc[4]\n",
    "\n",
    "# list of years which was included in the data.\n",
    "year_list = [\"2019\", \"2020\", \"2021\", \"2022\", \"2023\"]\n",
    "\n",
    "def get_year_region_df(s):\n",
    "    # only keep those numbers.\n",
    "    s = s[2:]\n",
    "    nystate = [s.iloc[i] for i in range(len(year_list))]\n",
    "    nyc = [s.iloc[i + 5] for i in range(len(year_list))]\n",
    "    non_nyc = [s.iloc[i + 10] for i in range(len(year_list))]\n",
    "    df = pd.DataFrame({\n",
    "        # \"NYState\":nystate,\n",
    "        \"NYC\": nyc,\n",
    "        \"Non-NYC\": non_nyc\n",
    "    })\n",
    "    df.index = year_list\n",
    "    return df\n",
    "total_incidents_df = get_year_region_df(total_incidents_row)\n",
    "total_incidents_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cab2faf-2902-4c18-a390-0d791a9fae71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of non nyc hate crime data, used for generating Figure 1.\n",
    "# Since the datset I use for Figure 1 has no non nyc hate crime data.\n",
    "non_nyc_hate_crime_2023 = int(total_incidents_df.loc[\"2023\", \"Non-NYC\"])\n",
    "non_nyc_hate_crime_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc62e93-1e0a-4128-a896-e80331842866",
   "metadata": {},
   "outputs": [],
   "source": [
    "HATE_CRIME_BY_COUNTY_BIAS_BEGINNING_2010 = r\"data\\hatecrime_by_county.csv\"\n",
    "\n",
    "# doesn't exist, use Socrata to get the data\n",
    "if not os.path.exists(HATE_CRIME_BY_COUNTY_BIAS_BEGINNING_2010):\n",
    "    client = Socrata(\"data.ny.gov\", app_token=None)\n",
    "    res = client.get(\"6xda-q7ev\", limit=1000)\n",
    "    res_df = pd.DataFrame.from_records(res)\n",
    "    res_df.to_csv(HATE_CRIME_BY_COUNTY_BIAS_BEGINNING_2010, index=False)\n",
    "\n",
    "# read the data from csv\n",
    "df = pd.read_csv(HATE_CRIME_BY_COUNTY_BIAS_BEGINNING_2010)\n",
    "# those county located in New York State\n",
    "nyc_county_list = [\"Bronx\", \"Kings\", \"New York\", \"Queens\", \"Richmond\"]\n",
    "# set incidents type to int. If we don't do this step, the output will be 350.0(float). Doesn't look good.\n",
    "df[\"total_incidents\"] = df[\"total_incidents\"].astype(int)\n",
    "\n",
    "# county in the list(nyc counties), groupby year, total_incidents sum.\n",
    "s1 = df[df[\"county\"].isin(nyc_county_list)].groupby(\"year\")[[\"total_incidents\"]].sum()\n",
    "# county not in nyc.\n",
    "s2 = df[~ df[\"county\"].isin(nyc_county_list)].groupby(\"year\")[[\"total_incidents\"]].sum()\n",
    "hate_crimes_nyc_ros = pd.concat([s1, s2], axis=1, ignore_index=True)\n",
    "hate_crimes_nyc_ros = hate_crimes_nyc_ros.rename(columns={0: \"New York City\", 1: \"Rest of State\"})\n",
    "\n",
    "# find the row, whose index is 2023(create a new row)\n",
    "hate_crimes_nyc_ros.loc[2023] = [number_of_nyc_hate_crime_2023, non_nyc_hate_crime_2023]\n",
    "hate_crimes_nyc_ros.to_excel(\"beginning2010.xlsx\")\n",
    "hate_crimes_nyc_ros\n",
    "\n",
    "# Figure 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61dbfca0-bb51-4422-8f3a-1bd023949102",
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculated to support the differnece between nyc data and federal data.\n",
    "sub = hate_crimes_nyc_ros.loc[[2022, 2023]]\n",
    "total_2022_2023_nyc_df = sub[\"New York City\"] + sub[\"Rest of State\"]\n",
    "total_2022_2023_nyc_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a63abef-27d6-445d-acde-82e7126601ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this code scrawl from the web page. Aim to get the crime data of NY state hate crime data.\n",
    "# to understand this code you should go the webpage of this url and inspect the webpage.\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "res = requests.get(\"https://www.justice.gov/hatecrimes/state-data/new-york\")\n",
    "bs = BeautifulSoup(res.content,\"html.parser\")\n",
    "# find the first table. The Bias Motivation Cateogry by Year table.\n",
    "rows = bs.find(\"table\").find_all(\"tr\")\n",
    "# the first element is \"Bias Movivation Category\" should ignore.\n",
    "columns = [p.text for p in rows[0]][1:] \n",
    "df = pd.DataFrame(columns = [int(c) for c in columns])\n",
    "\n",
    "for row in rows[1:]:\n",
    "    # replace parse 1'048 to 1048, thus int() can parse it to integer successfully.\n",
    "    vals = [int(p.text.replace(',','')) for p in row.find_all(\"p\")]\n",
    "    # get the category of bias motivation\n",
    "    idx = row.find(\"strong\").text\n",
    "    df.loc[idx] = vals\n",
    "# explanation about 2021 data in the webpage:\n",
    "# 2021 was the first year that the annual hate crimes statistics were reported entirely\n",
    "# through the National Incident-Based Reporting System (NIBRS).  As a result of the shift \n",
    "# to NIBRS-only data collection, law enforcement agency participation in submitting all \n",
    "# crime statistics, including hate crimes, fell significantly from 2020 to 2021.  \n",
    "# so drop it.\n",
    "df.drop(2021, axis = 1, inplace = True)\n",
    "df = pd.concat([df.loc['Total:'],total_2022_2023_nyc_df], axis = 1, ignore_index = True)\n",
    "df.columns = [\"Federal Data\", \"NYC Data\"]\n",
    "df\n",
    "\n",
    "# Table 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9864b6-71fd-48ae-a6e1-94073302eda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Source need to manually download from https://cde.ucr.cjis.gov/LATEST/webapp/#/pages/downloads#nibrs-downloads\n",
    "NIBRS_HATECRIME_DATA = r\"data\\nibrs\\hate_crime\\hate_crime.csv\"\n",
    "df = pd.read_csv(NIBRS_HATECRIME_DATA)\n",
    "\n",
    "# first step, only need NY state data.\n",
    "df = df[df[\"state_abbr\"] == \"NY\"]\n",
    "# New York City, year range 2019-2024, Anti-Jewish data\n",
    "df = df[(df[\"pug_agency_name\"] == \"New York\") & (df[\"data_year\"].isin(list(range(2019, 2025))))]\n",
    "offender_race = df[\"offender_race\"].value_counts()\n",
    "offender_race.index.name = \"Offender Race\"\n",
    "offender_race.to_csv(\"offender_race.csv\")\n",
    "offender_race\n",
    "\n",
    "# Figure 5"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
